
students:
  individual:
    # Naming convention: student_{UniqueName} e.g. student_0 or student_zero.
    # Order is determined by order of listed item
    student_english:
      languages: [ "en" ]
    student_swahili:
      languages: [ "sw" ]
      
    
evaluation:
  # Can also use 'teacher' as model name: Evaluate with teacher

  #retrieval: null
  retrieval_cos_cls:
    evaluate_with:  # E.g. ((student_0, en), (student_0, ht))
      - ((student_swahili, sw), (student_english, en))
  retrieval_cos_mean:
    evaluate_with:  # E.g. ((student_0, en), (student_0, ht))
      - ((student_swahili, sw), (student_english, en))
  retrieval_bertscore:
    evaluate_with:  # E.g. ((student_0, en), (student_0, ht))
      - ((student_swahili, sw), (student_english, en))

  #mlm: null
  mlm:
    aggregate: false  # If multiple model-language available, then aggregate metrics or calculate separately
    evaluate_with:  # E.g. ((student_0, en), (student_0, ht)) <-> Using parallel data or (student_0, en) <-> not using parallel data
      - ((student_swahili, sw), (student_english, en))


callbacks:
  model_checkpoint:
    monitor: "val/retrieval_bertscore/student_swahili_sw-student_english_en/bertscore_mrr"
    every_n_train_steps: 5001 # add 1 to trainer.val_check_interval
    
datamodule:
  val_retrieval:
    max_length: 395
    batch_size: 1
  val_mlm:
    max_length: 395
    batch_size: 1
  train:
    batch_size: 2