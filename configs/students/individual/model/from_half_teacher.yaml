_target_: src.models.model.get_tiny_model

defaults:
  - xlmr.yaml

teacher: None

cfg:
  hidden_size: 768 # must be dividable by no. of heads!
  num_hidden_layers: 6

weights_from_teacher:
  embeddings: False
  transformer_blocks: False

mapping: {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5} # Careful! Layer numbering from 0. E.g. Bert has 0, ..., 11 layers!