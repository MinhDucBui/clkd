# @package _global_


students:
  individual:
    # Naming convention: student_{UniqueName} e.g. student_0 or student_zero.
    # Order is determined by order of listed item
    student_urdu:
      languages: [ "ur" ]
    student_swahili:
      languages: [ "sw" ]

  weight_sharing_across_students: false
  # Naming convention: ( ( {Student Name}, {Layer Number} ), ( {Student Name}, {Layer Number}) )
  # E.g. false or
  # - ((student_0, 1), (student_1, 1))
  # - ((student_0, 6), (student_1, 5))
  # Note: Embedding sharing is not allowed with this key (see key 'embed_sharing')

  embed_sharing:
    - ((student_swahili, sw), (student_urdu, ur))
  # E.g. "in_each_model" <-> Share embeddings between languages in each model
  # E.g. "in_overlapping_language" <-> Share embeddings between overlapping languages across models
  # E.g.
  # - ((student_1, ss), (student_0, ss))

evaluation:
  # Can also use 'teacher' as model name: Evaluate with teacher

  #retrieval: null
  retrieval_cos_cls:
    evaluate_with:  # E.g. ((student_0, en), (student_0, ht))
      - ((student_swahili, sw), (student_urdu, ur))
  retrieval_cos_mean:
    evaluate_with:  # E.g. ((student_0, en), (student_0, ht))
      - ((student_swahili, sw), (student_urdu, ur))
  retrieval_bertscore:
    evaluate_with:  # E.g. ((student_0, en), (student_0, ht))
      - ((student_swahili, sw), (student_urdu, ur))

  #mlm: null
  mlm:
    aggregate: false  # If multiple model-language available, then aggregate metrics or calculate separately
    evaluate_with:  # E.g. ((student_0, en), (student_0, ht)) <-> Using parallel data or (student_0, en) <-> not using parallel data
      - ((student_swahili, sw), (student_urdu, ur))


callbacks:
  model_checkpoint:
    monitor: "val/retrieval_bertscore/student_swahili_sw-student_student_urdu_ur/bertscore_mrr"
    every_n_train_steps: 5001 # add 1 to trainer.val_check_interval

datamodule:
  val_retrieval:
    max_length: 390
    batch_size: 1
  val_mlm:
    max_length: 390
    batch_size: 1
  train:
    batch_size: 2
