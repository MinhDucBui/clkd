_recursive_: false
_target_: src.distillation.adversarial_learning.AdversarialLearningLabelFlipping

validate_before_training: True

generator:
  strategy: "sequentually" # "jointly" = Train generator jointly with normal training step (distillation)
                      # "sequentually" = Train generator sequentually
  jointly_weight: 100
  optimizer:
    _target_: transformers.optimization.Adafactor
    weight_decay: 0.01
  train_models: ["student_english", "student_turkish"] # If you want to train all models, give "all" as a string or list all models
    
discriminator:
  architecture:
    n_hidden_layers: 2
    dropout_p: 0.2
    bias: True
    batch_norm: True
  optimizer:
    _target_: transformers.optimization.Adafactor
    weight_decay: 0.01